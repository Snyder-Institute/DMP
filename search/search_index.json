{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Data management plan (DMP) Every research group should implement a data management plan to ensure long-term sustainability Last updated: December 23, 2025 Why implement a DMP? A data management plan (DMP) establishes consistent, transparent, and sustainable practices for storing, organizing, and maintaining research data. Implementing a DMP provides the following benefits: Resource efficiency : Reduce storage costs and minimize researcher time spent locating, copying, or cleaning data. Effective disk usage tracking : Enable monitoring of quotas and usage at the user and project level. Reduction of redundancy and clutter : Prevent duplicated large files (for example, reference genomes) and eliminate orphaned or abandoned directories. Improved documentation and accountability : Clearly identify directory ownership, contents, and purpose to support data reuse and validation cohorts. Automation readiness : Support automated reporting of storage usage per user or project without manual inspection. Streamlined backup and archiving : Simplify long-term backup, archiving, and data restoration workflows. Common data management pitfalls The following practices significantly hinder scalability, reproducibility, and storage efficiency: Retaining large files in uncompressed formats Duplicating reference genomes and annotations across multiple directories Inconsistent directory depth and naming conventions Mixing unrelated content within a single directory, such as: Raw data Reference files Intermediate results Scripts and logs Final outputs Recommended directory structure All shared storage should be organized under FIVE root-level directories only : RAWDATA : primary, unprocessed data (for example, FASTQ files). RESULTS : version-controlled, processed datasets generated by standardized lab pipelines and intended for reuse. EXTERNAL : third-party datasets obtained from public repositories or published studies. REFERENCES : shared resources such as reference genomes, annotations, and indices. projects : active working space for analyses, scripts, and collaboration. Rationale for the five-folder model The separation into RAWDATA , RESULTS , EXTERNAL , REFERENCES , and projects is not cosmetic. Each folder has a distinct operational meaning that enables informed decisions about backup priority, cleanup strategy, and long-term sustainability: Predictable cleanup when storage reaches quota : When storage pressure occurs, projects is the first target for cleanup, followed by selective pruning of derived files. RAWDATA and RESULTS are protected from ad hoc deletion, reducing the risk of irreversible data loss. Clear backup prioritization : RAWDATA and RESULTS contain irreplaceable or high-value data and therefore receive the highest backup priority. In contrast, projects contains intermediate and reproducible outputs that can be regenerated if needed. Explicit separation of re-downloadable data : EXTERNAL is reserved exclusively for third-party datasets that can be re-downloaded from public repositories or publications. This prevents unnecessary backup of recoverable data and simplifies restoration strategies. Shared, single-source references : REFERENCES centralizes genomes, annotations, and indices that are shared across users and projects. This eliminates redundant copies, ensures consistency across analyses, and simplifies updates. Automated and interpretable storage accounting : A fixed set of root folders enables automated reporting of storage usage per category. Administrators can immediately assess how much space is consumed by raw data, results, references, external datasets, or active projects without manual inspection. Suggested subdirectory organization RAWDATA and RESULTS : Organized by sequencing run, cohort, or experiment EXTERNAL : Organized by PMID, consortium name, or study identifier REFERENCES : Hierarchical structure species \u2192 assembly \u2192 resource type (for example, genome, annotation, tool-specific index) projects : Flexible structure defined by project needs Recommended project-level directory layout Within each project directory, the following subfolders are encouraged: Documents : Metadata, sample annotations, and study notes FASTQ : Symbolic links pointing to raw data stored in RAWDATA Results : Intermediate and final analysis outputs specific to the project and finalized results should be copied to the RESULTS folder Scripts : Analysis scripts and Slurm job files, ideally under version control (for example, Git) Logs : Records of pipeline runs, errors, and processing step Special notes on the projects folder Intended for intermediate files and active analyses Subject to regular cleanup First target for space reclamation when storage is limited Symbolic links should be used to avoid data duplication Additional guidelines Every RAWDATA and projects folder must contain a README.txt Shared directories under /work and /bulk must use 750 permissions Directory names are capitalized to indicate controlled, shared resources README files (mandatory) Every project directory and the RAWDATA directory must include a README file. README files may be free-form but should, at minimum, record: Date of creation or update Project or sample description Data source Ownership and responsible contact Key processing steps or assumptions Examples below: ## Under RAWDATA folder # Project: MICROBENCH # Generated: Jared Schlechte # README by: Heewon Seo # Date: November 06, 2025 # Data format: POD5 # Data source: Oxfort Nanopore # Description: This folder contains raw Nanopore sequencing data (POD5 files) along with automatically generated statistics and report files from MinKNOW. Some report files are missing due to MinKNOW processing failures. ## Under RESULTS folder # Project: MICROBENCH # Generated: Heewon Seo # Date: November 10, 2025 # Data format: BAM and FASTQ # Data source: Oxfort Nanopore # Description: This folder contains unaligned BAM files from each plate and barcode-level FASTQ files that were generated from POD5 files using the Griffin-Pipeline (https://github.com/Snyder-Institute/Griffin-Pipeline). Permissions and ownership Shared directories Use 750 (or 770 when appropriate) permissions Allow group-level read access while preserving ownership clarity Example commands: chmod -R 750 FOLDER_NAME chmod 750 FILE_NAME Default permissions Add the following to your .bash_profile : umask 0027 Group ownership chown -R heewon.seo:bioinformatics_hub FOLDER_NAME chgrp -R bioinformatics_hub FOLDER_NAME Immutable read-only data Symbolic links Use symbolic links to reference shared, immutable data: ln -s SOURCE_FILE DEST_FILE unlink DEST_FILE Environment variables Define shortcuts for frequently used directories: Create ~/.bash_env : REFERENCES=/work/bioinformatics_hub/REFERENCES/ Source it in .bash_profile : if [ -f ~/.bash_env ]; then source ~/.bash_env fi Backup and archiving strategy The backup system follows the 3-2-1 rule : Maintain three copies of all critical data Store data on two different types of media Keep one copy offsite Additional notes: Backup failover storage is offline, not internet-connected, and inaccessible to users to maximize data security. ResearchFS provides a scratch-style projects workspace that supports active analyses without disrupting existing workflows.","title":"DMP"},{"location":"index.html#data-management-plan-dmp","text":"Every research group should implement a data management plan to ensure long-term sustainability Last updated: December 23, 2025","title":"Data management plan (DMP)"},{"location":"index.html#why-implement-a-dmp","text":"A data management plan (DMP) establishes consistent, transparent, and sustainable practices for storing, organizing, and maintaining research data. Implementing a DMP provides the following benefits: Resource efficiency : Reduce storage costs and minimize researcher time spent locating, copying, or cleaning data. Effective disk usage tracking : Enable monitoring of quotas and usage at the user and project level. Reduction of redundancy and clutter : Prevent duplicated large files (for example, reference genomes) and eliminate orphaned or abandoned directories. Improved documentation and accountability : Clearly identify directory ownership, contents, and purpose to support data reuse and validation cohorts. Automation readiness : Support automated reporting of storage usage per user or project without manual inspection. Streamlined backup and archiving : Simplify long-term backup, archiving, and data restoration workflows.","title":"Why implement a DMP?"},{"location":"index.html#common-data-management-pitfalls","text":"The following practices significantly hinder scalability, reproducibility, and storage efficiency: Retaining large files in uncompressed formats Duplicating reference genomes and annotations across multiple directories Inconsistent directory depth and naming conventions Mixing unrelated content within a single directory, such as: Raw data Reference files Intermediate results Scripts and logs Final outputs","title":"Common data management pitfalls"},{"location":"index.html#recommended-directory-structure","text":"All shared storage should be organized under FIVE root-level directories only : RAWDATA : primary, unprocessed data (for example, FASTQ files). RESULTS : version-controlled, processed datasets generated by standardized lab pipelines and intended for reuse. EXTERNAL : third-party datasets obtained from public repositories or published studies. REFERENCES : shared resources such as reference genomes, annotations, and indices. projects : active working space for analyses, scripts, and collaboration.","title":"Recommended directory structure"},{"location":"index.html#rationale-for-the-five-folder-model","text":"The separation into RAWDATA , RESULTS , EXTERNAL , REFERENCES , and projects is not cosmetic. Each folder has a distinct operational meaning that enables informed decisions about backup priority, cleanup strategy, and long-term sustainability: Predictable cleanup when storage reaches quota : When storage pressure occurs, projects is the first target for cleanup, followed by selective pruning of derived files. RAWDATA and RESULTS are protected from ad hoc deletion, reducing the risk of irreversible data loss. Clear backup prioritization : RAWDATA and RESULTS contain irreplaceable or high-value data and therefore receive the highest backup priority. In contrast, projects contains intermediate and reproducible outputs that can be regenerated if needed. Explicit separation of re-downloadable data : EXTERNAL is reserved exclusively for third-party datasets that can be re-downloaded from public repositories or publications. This prevents unnecessary backup of recoverable data and simplifies restoration strategies. Shared, single-source references : REFERENCES centralizes genomes, annotations, and indices that are shared across users and projects. This eliminates redundant copies, ensures consistency across analyses, and simplifies updates. Automated and interpretable storage accounting : A fixed set of root folders enables automated reporting of storage usage per category. Administrators can immediately assess how much space is consumed by raw data, results, references, external datasets, or active projects without manual inspection.","title":"Rationale for the five-folder model"},{"location":"index.html#suggested-subdirectory-organization","text":"RAWDATA and RESULTS : Organized by sequencing run, cohort, or experiment EXTERNAL : Organized by PMID, consortium name, or study identifier REFERENCES : Hierarchical structure species \u2192 assembly \u2192 resource type (for example, genome, annotation, tool-specific index) projects : Flexible structure defined by project needs","title":"Suggested subdirectory organization"},{"location":"index.html#recommended-project-level-directory-layout","text":"Within each project directory, the following subfolders are encouraged: Documents : Metadata, sample annotations, and study notes FASTQ : Symbolic links pointing to raw data stored in RAWDATA Results : Intermediate and final analysis outputs specific to the project and finalized results should be copied to the RESULTS folder Scripts : Analysis scripts and Slurm job files, ideally under version control (for example, Git) Logs : Records of pipeline runs, errors, and processing step","title":"Recommended project-level directory layout"},{"location":"index.html#special-notes-on-the-projects-folder","text":"Intended for intermediate files and active analyses Subject to regular cleanup First target for space reclamation when storage is limited Symbolic links should be used to avoid data duplication","title":"Special notes on the projects folder"},{"location":"index.html#additional-guidelines","text":"Every RAWDATA and projects folder must contain a README.txt Shared directories under /work and /bulk must use 750 permissions Directory names are capitalized to indicate controlled, shared resources","title":"Additional guidelines"},{"location":"index.html#readme-files-mandatory","text":"Every project directory and the RAWDATA directory must include a README file. README files may be free-form but should, at minimum, record: Date of creation or update Project or sample description Data source Ownership and responsible contact Key processing steps or assumptions Examples below: ## Under RAWDATA folder # Project: MICROBENCH # Generated: Jared Schlechte # README by: Heewon Seo # Date: November 06, 2025 # Data format: POD5 # Data source: Oxfort Nanopore # Description: This folder contains raw Nanopore sequencing data (POD5 files) along with automatically generated statistics and report files from MinKNOW. Some report files are missing due to MinKNOW processing failures. ## Under RESULTS folder # Project: MICROBENCH # Generated: Heewon Seo # Date: November 10, 2025 # Data format: BAM and FASTQ # Data source: Oxfort Nanopore # Description: This folder contains unaligned BAM files from each plate and barcode-level FASTQ files that were generated from POD5 files using the Griffin-Pipeline (https://github.com/Snyder-Institute/Griffin-Pipeline).","title":"README files (mandatory)"},{"location":"index.html#permissions-and-ownership","text":"","title":"Permissions and ownership"},{"location":"index.html#shared-directories","text":"Use 750 (or 770 when appropriate) permissions Allow group-level read access while preserving ownership clarity Example commands: chmod -R 750 FOLDER_NAME chmod 750 FILE_NAME","title":"Shared directories"},{"location":"index.html#default-permissions","text":"Add the following to your .bash_profile : umask 0027","title":"Default permissions"},{"location":"index.html#group-ownership","text":"chown -R heewon.seo:bioinformatics_hub FOLDER_NAME chgrp -R bioinformatics_hub FOLDER_NAME","title":"Group ownership"},{"location":"index.html#immutable-read-only-data","text":"","title":"Immutable read-only data"},{"location":"index.html#symbolic-links","text":"Use symbolic links to reference shared, immutable data: ln -s SOURCE_FILE DEST_FILE unlink DEST_FILE","title":"Symbolic links"},{"location":"index.html#environment-variables","text":"Define shortcuts for frequently used directories: Create ~/.bash_env : REFERENCES=/work/bioinformatics_hub/REFERENCES/ Source it in .bash_profile : if [ -f ~/.bash_env ]; then source ~/.bash_env fi","title":"Environment variables"},{"location":"index.html#backup-and-archiving-strategy","text":"The backup system follows the 3-2-1 rule : Maintain three copies of all critical data Store data on two different types of media Keep one copy offsite Additional notes: Backup failover storage is offline, not internet-connected, and inaccessible to users to maximize data security. ResearchFS provides a scratch-style projects workspace that supports active analyses without disrupting existing workflows.","title":"Backup and archiving strategy"},{"location":"arc.html","text":"Advanced Research Computing (ARC) Help everyone understand the options available so we can fully utilize the ARC resources available to us Last updated: January 13, 2026 ARC folder permissions In research computing, shared storage is intended to support collaboration\u2014especially for commonly reused reference datasets (e.g., human/mouse genomes) that should not be repeatedly downloaded and duplicated across users. However, the default folder setup often doesn\u2019t make collaboration easy . A common problem is that when someone creates a file inside a shared folder, the file may end up owned primarily by that individual rather than by the lab/group. In practical terms, this can mean other lab members cannot read or modify the file\u2014even though it sits in a \u201cshared\u201d location\u2014unless the permissions are manually adjusted. Ideally, shared folders should be configured so that new files automatically inherit the lab/group ownership (not just the creator\u2019s personal ownership) and come with group-friendly permissions by default. Without that \u201cinheritance\u201d setting, sharing becomes inconsistent: people have to fix access case-by-case, and unless users explicitly ask the admins to adjust the configuration, the shared space can remain difficult to use for day-to-day collaboration. As a result: New users often re-download the reference files because they cannot access shared copies. Many users are unsure how permissions work or how to fix access issues. In the worst case, folders end up set to overly permissive modes (e.g., 777 ) as a quick workaround, which is not secure and can violate licensing restrictions. Practical action : You can email ARC admins and request that your shared storage space be configured so that files created within shared folders automatically inherit the correct group ownership and permissions (commonly done via group sticky bit / setgid configuration and appropriate default permissions). Check your folders You can verify your shared folder permissions by running the following command: ls -ahl Then review the output: Owner and Group columns : The owner should not be your personal username. The group should be your lab/group name (the group you intend to share with). Mode/permissions (first column): Your folder should not be set to something like rwxrwxrwx (world-readable/writable/executable). If permissions are world-accessible, the shared group is effectively meaningless because other users on ARC could list and browse your folders. What are permissions On Linux, file access is controlled in three \u201ctiers\u201d: Owner (u): the file owner (usually you) Group (g): a defined set of users (e.g., your lab group) Others (o): everyone else on the system Each tier can have three basic permissions: r (read): can view/open the file (or list a directory) w (write): can edit the file (or create/delete within a directory, depending on directory permissions) x (execute): can run a program/script; for directories, this means \u201ccan enter/access\u201d the directory How to read mode/permissions Each entry is shown as 1 type character followed by 9 permission characters, where the 9 permissions are split into three triplets (user, group, others). You\u2019ll often see something like this: drwxr-s--- : d (the very first character indicates the type): a directory Owner (first three): rwx (owner can read, write/modify, and execute) Group (second three): r-s (group can read and enter) Others (third three): --- (no access) -rw-r----- : - : a file Owner : rw- (owner can read and write) Group : r-- (group can read) Others : --- (no access) Interpreting 777 (rwxrwxrwx) These values add up per scope (owner/group/others). So rwx = 4 + 2 + 1 = 7, and 777 means rwx for onwer, rwx for group, rwx for others. r = 4 w = 2 x = 1 Recommended settings If you\u2019re not sure how to explain the issue to ARC admins, you can simply ask them to configure the shared directory by setting the group sticky bit so that files and folders created inside automatically inherit the lab\u2019s group ownership and appropriate permissions. This enables sharing by default and avoids manual fixes later. Enable group inheritance (setgid bit, g+s ) Ensures that new files and subfolders created in the shared directory belong to the lab group, not just the individual who created them. Use sensible default permissions (avoid 777 ) Shared lab data should be accessible to lab members, but not open to everyone on the system. This improves security and helps maintain compliance with data- and license-related restrictions. Permission misuse and licensing example: KEGG The KEGG database is a valuable resource in medical research and it is not free. Per KEGG\u2019s licensing and access rules, downloaded KEGG resources generally must not be redistributed to non-subscribers; only authorized users should access them. KEGG-related folders sometimes end up set to overly permissive permissions (e.g., 777 ) because users have limited familiarity with Linux permissions. This creates a compliance and risk issue. Recommendation : Keep KEGG data restricted to authorized users only (typically not world-readable). If you are unsure whether your group is properly licensed or how access should be configured, treat KEGG data as restricted and consult a knowledgeable expert before sharing. ARC file system Most research data today is large, and while traditional file systems can still function, they clearly have limitations at scale. Many research institutions have already moved toward modern parallel file systems\u2014such as Lustre or BeeGFS (developed by the Fraunhofer Society)\u2014to better support data-intensive workloads. At UCalgary, however, ARC primarily relies on NFS (Network File System). Confirming the current ARC file system You can verify the file system type directly on ARC using standard Linux commands. For example: $ df -T /work Filesystem Type netapp1:/ArcWork nfs $ df -T /bulk Filesystem Type bulknetapp1:/Bulk nfs This output confirms that both /work and /bulk are mounted using NFS. Limitations of NFS in shared HPC environments The main limitation of NFS is that it does not scale well under heavy or concurrent use. When one user performs intensive I/O (for example, reading or writing large files), it can temporarily block or slow access for other users. In practice, this often results in: Noticeable I/O \u201changs\u201d during peak usage Reduced performance when working with large datasets Bottlenecks when many users access the same storage simultaneously Benefits of modern parallel file systems in research computing Parallel file systems are designed specifically for HPC environments. They allow many users and compute nodes to read and write data at the same time without significantly interfering with one another, and they scale far more effectively as data size and user count increase. Examples of modern file systems in practice: Lustre was introduced in the early 2000s and is widely used in large-scale HPC environments. It has been deployed at NASA, Oak Ridge National Laboratory, and many systems on the TOP500 supercomputer list. BeeGFS (by the Fraunhofer Society in Germany) is also widely adopted in academic and research institutions, particularly in Europe, due to its flexibility and strong performance for parallel workloads. Beyond performance, these modern file systems also offer stronger data-integrity features and are better suited for structured backup and redundancy strategies . Given that ARC does not currently provide comprehensive backups, moving toward a modern file system would be a meaningful long-term investment in data safety and research reliability. Each advanced file system has its own strengths and trade-offs, and choosing between them requires careful technical and operational consideration. That decision is beyond the scope of this discussion. However, the more fundamental point is that moving away from a purely NFS-based model would significantly improve the research computing environment overall. ARC outage scheduling ARC outages at UCalgary are often scheduled on weekdays during daytime hours, which tends to maximize disruption for users. In many commercial environments, this would be considered unacceptable (e.g., not being able to access Outlook during work hours). Even in academia, the typical practice is to schedule maintenance to minimize interruption for end users (for example, evenings, nights, or weekends when feasible). This scheduling culture feels somewhat unique here and has a real impact on productivity.","title":"ARC"},{"location":"arc.html#advanced-research-computing-arc","text":"Help everyone understand the options available so we can fully utilize the ARC resources available to us Last updated: January 13, 2026","title":"Advanced Research Computing (ARC)"},{"location":"arc.html#arc-folder-permissions","text":"In research computing, shared storage is intended to support collaboration\u2014especially for commonly reused reference datasets (e.g., human/mouse genomes) that should not be repeatedly downloaded and duplicated across users. However, the default folder setup often doesn\u2019t make collaboration easy . A common problem is that when someone creates a file inside a shared folder, the file may end up owned primarily by that individual rather than by the lab/group. In practical terms, this can mean other lab members cannot read or modify the file\u2014even though it sits in a \u201cshared\u201d location\u2014unless the permissions are manually adjusted. Ideally, shared folders should be configured so that new files automatically inherit the lab/group ownership (not just the creator\u2019s personal ownership) and come with group-friendly permissions by default. Without that \u201cinheritance\u201d setting, sharing becomes inconsistent: people have to fix access case-by-case, and unless users explicitly ask the admins to adjust the configuration, the shared space can remain difficult to use for day-to-day collaboration. As a result: New users often re-download the reference files because they cannot access shared copies. Many users are unsure how permissions work or how to fix access issues. In the worst case, folders end up set to overly permissive modes (e.g., 777 ) as a quick workaround, which is not secure and can violate licensing restrictions. Practical action : You can email ARC admins and request that your shared storage space be configured so that files created within shared folders automatically inherit the correct group ownership and permissions (commonly done via group sticky bit / setgid configuration and appropriate default permissions).","title":"ARC folder permissions"},{"location":"arc.html#check-your-folders","text":"You can verify your shared folder permissions by running the following command: ls -ahl Then review the output: Owner and Group columns : The owner should not be your personal username. The group should be your lab/group name (the group you intend to share with). Mode/permissions (first column): Your folder should not be set to something like rwxrwxrwx (world-readable/writable/executable). If permissions are world-accessible, the shared group is effectively meaningless because other users on ARC could list and browse your folders.","title":"Check your folders"},{"location":"arc.html#what-are-permissions","text":"On Linux, file access is controlled in three \u201ctiers\u201d: Owner (u): the file owner (usually you) Group (g): a defined set of users (e.g., your lab group) Others (o): everyone else on the system Each tier can have three basic permissions: r (read): can view/open the file (or list a directory) w (write): can edit the file (or create/delete within a directory, depending on directory permissions) x (execute): can run a program/script; for directories, this means \u201ccan enter/access\u201d the directory","title":"What are permissions"},{"location":"arc.html#how-to-read-modepermissions","text":"Each entry is shown as 1 type character followed by 9 permission characters, where the 9 permissions are split into three triplets (user, group, others). You\u2019ll often see something like this: drwxr-s--- : d (the very first character indicates the type): a directory Owner (first three): rwx (owner can read, write/modify, and execute) Group (second three): r-s (group can read and enter) Others (third three): --- (no access) -rw-r----- : - : a file Owner : rw- (owner can read and write) Group : r-- (group can read) Others : --- (no access)","title":"How to read mode/permissions"},{"location":"arc.html#interpreting-777-rwxrwxrwx","text":"These values add up per scope (owner/group/others). So rwx = 4 + 2 + 1 = 7, and 777 means rwx for onwer, rwx for group, rwx for others. r = 4 w = 2 x = 1","title":"Interpreting 777 (rwxrwxrwx)"},{"location":"arc.html#recommended-settings","text":"If you\u2019re not sure how to explain the issue to ARC admins, you can simply ask them to configure the shared directory by setting the group sticky bit so that files and folders created inside automatically inherit the lab\u2019s group ownership and appropriate permissions. This enables sharing by default and avoids manual fixes later. Enable group inheritance (setgid bit, g+s ) Ensures that new files and subfolders created in the shared directory belong to the lab group, not just the individual who created them. Use sensible default permissions (avoid 777 ) Shared lab data should be accessible to lab members, but not open to everyone on the system. This improves security and helps maintain compliance with data- and license-related restrictions.","title":"Recommended settings"},{"location":"arc.html#permission-misuse-and-licensing-example-kegg","text":"The KEGG database is a valuable resource in medical research and it is not free. Per KEGG\u2019s licensing and access rules, downloaded KEGG resources generally must not be redistributed to non-subscribers; only authorized users should access them. KEGG-related folders sometimes end up set to overly permissive permissions (e.g., 777 ) because users have limited familiarity with Linux permissions. This creates a compliance and risk issue. Recommendation : Keep KEGG data restricted to authorized users only (typically not world-readable). If you are unsure whether your group is properly licensed or how access should be configured, treat KEGG data as restricted and consult a knowledgeable expert before sharing.","title":"Permission misuse and licensing example: KEGG"},{"location":"arc.html#arc-file-system","text":"Most research data today is large, and while traditional file systems can still function, they clearly have limitations at scale. Many research institutions have already moved toward modern parallel file systems\u2014such as Lustre or BeeGFS (developed by the Fraunhofer Society)\u2014to better support data-intensive workloads. At UCalgary, however, ARC primarily relies on NFS (Network File System).","title":"ARC file system"},{"location":"arc.html#confirming-the-current-arc-file-system","text":"You can verify the file system type directly on ARC using standard Linux commands. For example: $ df -T /work Filesystem Type netapp1:/ArcWork nfs $ df -T /bulk Filesystem Type bulknetapp1:/Bulk nfs This output confirms that both /work and /bulk are mounted using NFS.","title":"Confirming the current ARC file system"},{"location":"arc.html#limitations-of-nfs-in-shared-hpc-environments","text":"The main limitation of NFS is that it does not scale well under heavy or concurrent use. When one user performs intensive I/O (for example, reading or writing large files), it can temporarily block or slow access for other users. In practice, this often results in: Noticeable I/O \u201changs\u201d during peak usage Reduced performance when working with large datasets Bottlenecks when many users access the same storage simultaneously","title":"Limitations of NFS in shared HPC environments"},{"location":"arc.html#benefits-of-modern-parallel-file-systems-in-research-computing","text":"Parallel file systems are designed specifically for HPC environments. They allow many users and compute nodes to read and write data at the same time without significantly interfering with one another, and they scale far more effectively as data size and user count increase. Examples of modern file systems in practice: Lustre was introduced in the early 2000s and is widely used in large-scale HPC environments. It has been deployed at NASA, Oak Ridge National Laboratory, and many systems on the TOP500 supercomputer list. BeeGFS (by the Fraunhofer Society in Germany) is also widely adopted in academic and research institutions, particularly in Europe, due to its flexibility and strong performance for parallel workloads. Beyond performance, these modern file systems also offer stronger data-integrity features and are better suited for structured backup and redundancy strategies . Given that ARC does not currently provide comprehensive backups, moving toward a modern file system would be a meaningful long-term investment in data safety and research reliability. Each advanced file system has its own strengths and trade-offs, and choosing between them requires careful technical and operational consideration. That decision is beyond the scope of this discussion. However, the more fundamental point is that moving away from a purely NFS-based model would significantly improve the research computing environment overall.","title":"Benefits of modern parallel file systems in research computing"},{"location":"arc.html#arc-outage-scheduling","text":"ARC outages at UCalgary are often scheduled on weekdays during daytime hours, which tends to maximize disruption for users. In many commercial environments, this would be considered unacceptable (e.g., not being able to access Outlook during work hours). Even in academia, the typical practice is to schedule maintenance to minimize interruption for end users (for example, evenings, nights, or weekends when feasible). This scheduling culture feels somewhat unique here and has a real impact on productivity.","title":"ARC outage scheduling"}]}